import { type ActionFunctionArgs } from '@remix-run/cloudflare';
import { createScopedLogger } from '~/utils/logger';
import { withV8AuthUser } from '~/lib/verse8/middleware';

// @ts-ignore - Task Master module doesn't have TypeScript declarations
import { parsePRD } from 'task-master-ai/scripts/modules/task-manager';
import fs from 'fs';
import path from 'path';
import os from 'os';

export const action = withV8AuthUser(taskAction, { checkCredit: true });

const logger = createScopedLogger('api.task');

interface TaskBreakdownRequest {
  userPrompt: string;
}

interface TaskMasterTask {
  id: string;
  title: string;
  description: string;
  type?: string;
  priority: string;
  estimatedTime?: string;
  dependencies: string[];
  details?: string;
  testStrategy?: string;
  status?: string;
}

interface TaskMasterResult {
  summary: string;
  tasks: TaskMasterTask[];
  totalTasks: number;
  generatedAt: string;
  metadata?: {
    projectName: string;
    sourceFile: string;
  };
}

async function callTaskMasterAPI(prompt: string, env: any): Promise<TaskMasterResult> {
  try {
    logger.info('Calling Task Master API for autonomous task breakdown');

    const hasAnthropicKey = env.ANTHROPIC_API_KEY;
    const hasOpenAIKey = env.OPENAI_API_KEY;

    if (!hasAnthropicKey && !hasOpenAIKey) {
      throw new Error(
        'No LLM API keys found. Please set ANTHROPIC_API_KEY or OPENAI_API_KEY in environment variables.',
      );
    }

    logger.debug(`API Keys available: Anthropic=${!!hasAnthropicKey}, OpenAI=${!!hasOpenAIKey}`);

    const tempDir = os.tmpdir();
    const tempPrdFile = path.join(tempDir, `prd-${Date.now()}-${Math.random().toString(36).substring(7)}.txt`);
    const tempTasksFile = path.join(tempDir, `tasks-${Date.now()}-${Math.random().toString(36).substring(7)}.json`);

    try {
      // Write the user prompt directly - let LLM decide completely
      fs.writeFileSync(tempPrdFile, prompt, 'utf8');
      logger.debug(`Created temporary PRD file: ${tempPrdFile}`);

      // Set up environment variables
      process.env.ANTHROPIC_API_KEY = env.ANTHROPIC_API_KEY;
      process.env.OPENAI_API_KEY = env.OPENAI_API_KEY;
      process.env.GOOGLE_API_KEY = env.GOOGLE_API_KEY;

      logger.info('Calling Task Master parsePRD function with autonomous mode');

      // Pass 0 to let LLM decide autonomously (will result in "approximately 0" in prompt)
      await parsePRD(tempPrdFile, tempTasksFile, 0, {
        force: true,
        append: false,
        research: false,
        mcpLog: {
          info: (msg: string) => logger.info(`TaskMaster: ${msg}`),
          warn: (msg: string) => logger.warn(`TaskMaster: ${msg}`),
          error: (msg: string) => logger.error(`TaskMaster: ${msg}`),
          debug: (msg: string) => logger.debug(`TaskMaster: ${msg}`),
          success: (msg: string) => logger.info(`TaskMaster SUCCESS: ${msg}`),
        },
      });

      // Read the generated tasks
      if (!fs.existsSync(tempTasksFile)) {
        throw new Error('Task Master did not generate tasks file');
      }

      const tasksData = JSON.parse(fs.readFileSync(tempTasksFile, 'utf8'));
      logger.info(`LLM autonomously generated ${tasksData.tasks?.length || 0} tasks`);

      // Transform Task Master format to our expected format
      const transformedTasks: TaskMasterTask[] = (tasksData.tasks || []).map((task: any) => ({
        id: task.id?.toString() || 'unknown',
        title: task.title || 'Untitled Task',
        description: task.description || '',
        type: 'development',
        priority: task.priority || 'medium',
        dependencies: (task.dependencies || []).map((dep: number) => dep.toString()),
        details: task.details || '',
        testStrategy: task.testStrategy || '',
        status: task.status || 'pending',
      }));

      const result: TaskMasterResult = {
        summary: `Autonomous task breakdown: ${transformedTasks.length} tasks generated by LLM analysis for: ${prompt.slice(0, 100)}${prompt.length > 100 ? '...' : ''}`,
        tasks: transformedTasks,
        totalTasks: transformedTasks.length,
        generatedAt: new Date().toISOString(),
        metadata: tasksData.metadata || {
          projectName: 'User Request',
          sourceFile: 'API Request',
        },
      };

      return result;
    } finally {
      // Clean up temporary files
      try {
        if (fs.existsSync(tempPrdFile)) {
          fs.unlinkSync(tempPrdFile);
          logger.debug(`Cleaned up temporary PRD file: ${tempPrdFile}`);
        }

        if (fs.existsSync(tempTasksFile)) {
          fs.unlinkSync(tempTasksFile);
          logger.debug(`Cleaned up temporary tasks file: ${tempTasksFile}`);
        }
      } catch (cleanupError) {
        logger.warn(`Failed to clean up temporary files: ${cleanupError}`);
      }
    }
  } catch (error: any) {
    logger.error('Autonomous Task Master API call failed:', error);
    throw new Error(`Autonomous Task Master failed: ${error.message}`);
  }
}

async function taskAction({ request }: ActionFunctionArgs) {
  try {
    const body = await request.json<TaskBreakdownRequest>();
    const { userPrompt } = body;

    if (!userPrompt?.trim()) {
      return Response.json(
        {
          success: false,
          error: 'userPrompt is required',
        },
        { status: 400 },
      );
    }

    logger.info(`Autonomous task breakdown: ${userPrompt.slice(0, 100)}...`);

    const env = process.env;
    const taskBreakdown = await callTaskMasterAPI(userPrompt, env);

    logger.info(`LLM autonomously generated ${taskBreakdown.tasks.length} tasks`);

    return Response.json({
      success: true,
      data: {
        summary: taskBreakdown.summary,
        tasks: taskBreakdown.tasks,
        totalTasks: taskBreakdown.totalTasks,
        generatedAt: taskBreakdown.generatedAt,
        originalPrompt: userPrompt,
        metadata: taskBreakdown.metadata,
        apiKeysConfigured: {
          anthropic: !!env.ANTHROPIC_API_KEY,
          openai: !!env.OPENAI_API_KEY,
          google: !!env.GOOGLE_API_KEY,
        },
      },
    });
  } catch (error: any) {
    logger.error('Autonomous task breakdown failed:', error);

    return Response.json(
      {
        success: false,
        error: error.message || 'Autonomous task breakdown failed',
        details: error.stack,
      },
      { status: 500 },
    );
  }
}
